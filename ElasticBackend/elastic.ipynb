{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XU4UjiHpYdDT"
   },
   "source": [
    "# Simplified Vector Search (kNN) Implementation Guide\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5lV5UN90l4YN"
   },
   "source": [
    "# Loading the Embedding Model\n",
    "Loading embedding model: [sentence-transformers/all-distilroberta-v1](https://huggingface.co/sentence-transformers/all-distilroberta-v1)\n",
    "\n",
    "Loading code borrowed from [elasticsearch-labs](https://www.elastic.co/search-labs) NLP text search [example notebook](https://colab.research.google.com/github/elastic/elasticsearch-labs/blob/main/notebooks/integrations/hugging-face/loading-model-from-hugging-face.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch==2.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Riwvd3CHO9qU"
   },
   "outputs": [],
   "source": [
    "# import modules\n",
    "import pandas as pd, json\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.helpers import bulk\n",
    "from getpass import getpass\n",
    "from urllib.request import urlopen\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "So9bJJDVNzgF"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'name': 'e230fd301e9b', 'cluster_name': 'docker-cluster', 'cluster_uuid': 'S3u4N1xWQJ--WBh1mpUODQ', 'version': {'number': '9.0.0', 'build_flavor': 'default', 'build_type': 'docker', 'build_hash': '112859b85d50de2a7e63f73c8fc70b99eea24291', 'build_date': '2025-04-08T15:13:46.049795831Z', 'build_snapshot': False, 'lucene_version': '10.1.0', 'minimum_wire_compatibility_version': '8.18.0', 'minimum_index_compatibility_version': '8.0.0'}, 'tagline': 'You Know, for Search'})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "API_KEY = \"SjkteHBKWUJZcml2dGNPLTVSY1I6UVFnOXhPbF9PLTBLZUxRWEhIbERIZw==\"\n",
    "HUB_MODEL_ID = \"sentence-transformers/all-distilroberta-v1\"\n",
    "es = Elasticsearch(\"http://localhost:9200\", api_key=API_KEY)\n",
    "es.info()  # should return cluster info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dsFsmzZwpujb"
   },
   "outputs": [],
   "source": [
    "!eland_import_hub_model --url http://localhost:9200 --hub-model-id $HUB_MODEL_ID --task-type text_embedding --es-api-key $API_KEY --start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "71wNrH0vl4zi"
   },
   "source": [
    "# Ingest pipeline setup\n",
    "\n",
    "Map the field we want to create an embedding for, my_text, to the name the embedding model expects text_field in this case\n",
    "Configure which model to use with model_id. This is the name of the model within Elasticsearch\n",
    "Handle when any errors may occur for monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SL47BJNyl3-r",
    "outputId": "fa707db7-b6ec-47b4-c802-2d14c346e7bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acknowledged': True}\n"
     ]
    }
   ],
   "source": [
    "pipeline = {\n",
    "    \"processors\": [\n",
    "        {\n",
    "            \"inference\": {\n",
    "                \"field_map\": {\"my_text\": \"text_field\"},             # map model's text_field to my_text\n",
    "                \"model_id\": \"sentence-transformers__all-distilroberta-v1\",\n",
    "                \"target_field\": \"ml.inference.my_vector\",   # map model's output to my_vector\n",
    "                \"on_failure\": [\n",
    "                    {\n",
    "                        \"append\": {\n",
    "                            \"field\": \"_source._ingest.inference_errors\",\n",
    "                            \"value\": [\n",
    "                                {\n",
    "                                    \"message\": \"Processor 'inference' in pipeline 'ml-inference-title-vector' failed with message '{{ _ingest.on_failure_message }}'\",\n",
    "                                    \"pipeline\": \"ml-inference-title-vector\",\n",
    "                                    \"timestamp\": \"{{{ _ingest.timestamp }}}\",\n",
    "                                }\n",
    "                            ],\n",
    "                        }\n",
    "                    }\n",
    "                ],\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"set\": { # set the value of my_vector to the predicted_value\n",
    "                \"field\": \"my_vector\",\n",
    "                \"if\": \"ctx?.ml?.inference != null && ctx.ml.inference['my_vector'] != null\",    # check if the predicted_value is not null\n",
    "                \"copy_from\": \"ml.inference.my_vector.predicted_value\", # copy the predicted_value to my_vector\n",
    "                \"description\": \"Copy the predicted_value to 'my_vector'\", # description of the processor\n",
    "            }\n",
    "        },\n",
    "        {\"remove\": {\n",
    "            \"field\": \"ml.inference.my_vector\", # remove the ml.inference.my_vector field\n",
    "            \"ignore_missing\": True # ignore the missing field\n",
    "            }\n",
    "        },\n",
    "    ]\n",
    "}\n",
    "\n",
    "pipeline_id = \"vector_embedding_demo\"\n",
    "response = es.ingest.put_pipeline(id=pipeline_id, body=pipeline)\n",
    "\n",
    "# Print the response\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TgBeEw_Ql5I5"
   },
   "source": [
    "# Index Mapping / Template setup\n",
    "\n",
    "Embeddings (vectors) are stored in the dense_vector field type in Elasticsearch. Next we will configure the index template before indexing documents and generating embeddings.\n",
    "\n",
    "The below API call will create an index template to match any indices with the pattern my_vector_index-*\n",
    "\n",
    "It will:\n",
    "\n",
    "1.Configure dense_vector for my_vector as outlined in the documentation.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "2.It is recommended to Exclude the vector field from _source\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "3.We will also include one text field, my_text in this example which will be the source the embedding is generated from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I5F6DR8jroEM",
    "outputId": "f1222091-cd17-4d8a-d811-2ac8e55d944e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acknowledged': True}\n"
     ]
    }
   ],
   "source": [
    "index_patterns = [\"my_vector_index-*\"]\n",
    "\n",
    "priority = 1\n",
    "\n",
    "settings = {\n",
    "    \"index.default_pipeline\": pipeline_id,\n",
    "}\n",
    "\n",
    "mappings = {\n",
    "    \"properties\": {\n",
    "        \"my_vector\": {\"type\": \"dense_vector\", \"dims\": 768,\"index\": true, \"similarity\": \"dot_product\"},\n",
    "        \"my_text\": {\"type\": \"text\"},\n",
    "    },\n",
    "    \"_source\": {\"excludes\": [\"my_vector\"]},\n",
    "}\n",
    "\n",
    "# Exclude `my_vector` from `_source` explicitly\n",
    "source_exclusions = {\"_source\": {\"excludes\": [\"my_vector\"]}}\n",
    "\n",
    "# Create the index template using put_index_template\n",
    "response = es.indices.put_index_template(\n",
    "    name=\"my_vector_index_template\",  # Template name\n",
    "    index_patterns=index_patterns,\n",
    "    priority=priority,\n",
    "    template={\n",
    "        \"settings\": settings,\n",
    "        \"mappings\": mappings,\n",
    "    },\n",
    ")\n",
    "\n",
    "# Print the response\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bztQcxbll5cs"
   },
   "source": [
    "# Indexing Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bSIJ-AngVmUi",
    "outputId": "c5cdd475-132d-4410-83e8-3557f4e05bb5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'_shards': {'total': 2, 'successful': 1, 'failed': 0}})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_name = \"my_vector_index-01\"\n",
    "\n",
    "data = [\n",
    "    (\"Hey, careful, man, there's a beverage here!\", \"The Dude\"),\n",
    "    (\n",
    "        \"I’m The Dude. So, that’s what you call me. You know, that or, uh, His Dudeness, or, uh, Duder, or El Duderino, if you’re not into the whole brevity thing\",\n",
    "        \"The Dude\",\n",
    "    ),\n",
    "    (\n",
    "        \"You don't go out looking for a job dressed like that? On a weekday?\",\n",
    "        \"The Big Lebowski\",\n",
    "    ),\n",
    "    (\"What do you mean brought it bowling, Dude?\", \"Walter Sobchak\"),\n",
    "    (\n",
    "        \"Donny was a good bowler, and a good man. He was one of us. He was a man who loved the outdoors... and bowling, and as a surfer he explored the beaches of Southern California, from La Jolla to Leo Carrillo and... up to... Pismo\",\n",
    "        \"Walter Sobchak\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "actions = [\n",
    "    {\n",
    "        \"_op_type\": \"index\",\n",
    "        \"_index\": index_name,\n",
    "        \"_source\": {\"my_text\": text, \"my_metadata\": metadata},\n",
    "    }\n",
    "    for text, metadata in data\n",
    "]\n",
    "\n",
    "bulk(es, actions)\n",
    "\n",
    "# Refresh the index to make sure all data is searchable\n",
    "es.indices.refresh(index=index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ENlZ3Ndjl5yl"
   },
   "source": [
    "# Querying Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xk4CBDpimfDH"
   },
   "source": [
    "Approximate k-nearest neighbor (kNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xl76_rM4l3iC",
    "outputId": "5d3b4c44-ff3c-4489-b850-e2e1bfc4880a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'_id': 'ndmhrpYBca9xMcEAnock',\n",
      "  '_index': 'my_vector_index-01',\n",
      "  '_score': 0.7825787,\n",
      "  '_source': {'ml': {'inference': {}},\n",
      "              'my_metadata': 'The Dude',\n",
      "              'my_text': \"Hey, careful, man, there's a beverage here!\"}},\n",
      " {'_id': 'ntmhrpYBca9xMcEAnock',\n",
      "  '_index': 'my_vector_index-01',\n",
      "  '_score': 0.60257983,\n",
      "  '_source': {'ml': {'inference': {}},\n",
      "              'my_metadata': 'The Dude',\n",
      "              'my_text': 'I’m The Dude. So, that’s what you call me. You know, '\n",
      "                         'that or, uh, His Dudeness, or, uh, Duder, or El '\n",
      "                         'Duderino, if you’re not into the whole brevity '\n",
      "                         'thing'}}]\n"
     ]
    }
   ],
   "source": [
    "knn = {\n",
    "    \"field\": \"my_vector\",\n",
    "    \"k\": 2,\n",
    "    \"num_candidates\": 5,\n",
    "    \"query_vector_builder\": {\n",
    "        \"text_embedding\": {\n",
    "            \"model_id\": \"sentence-transformers__all-distilroberta-v1\",\n",
    "            \"model_text\": \"Watchout I have a drink\",    # Frontend will pass the text to be embedded\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n",
    "response = es.search(index=index_name, knn=knn, source=True)\n",
    "\n",
    "pprint(response[\"hits\"][\"hits\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'took': 8, 'timed_out': False, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}, 'hits': {'total': {'value': 2, 'relation': 'eq'}, 'max_score': 0.7825787, 'hits': [{'_index': 'my_vector_index-01', '_id': 'ndmhrpYBca9xMcEAnock', '_score': 0.7825787, '_source': {'my_text': \"Hey, careful, man, there's a beverage here!\", 'my_metadata': 'The Dude', 'ml': {'inference': {}}}}, {'_index': 'my_vector_index-01', '_id': 'ntmhrpYBca9xMcEAnock', '_score': 0.60257983, '_source': {'my_text': 'I’m The Dude. So, that’s what you call me. You know, that or, uh, His Dudeness, or, uh, Duder, or El Duderino, if you’re not into the whole brevity thing', 'my_metadata': 'The Dude', 'ml': {'inference': {}}}}]}})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response\n",
    "# ObjectApiResponse({'took': 8, 'timed_out': False, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}, 'hits': {'total': {'value': 2, 'relation': 'eq'}, 'max_score': 0.7825787, 'hits': [{'_index': 'my_vector_index-01', '_id': 'ndmhrpYBca9xMcEAnock', '_score': 0.7825787, '_source': {'my_text': \"Hey, careful, man, there's a beverage here!\", 'my_metadata': 'The Dude', 'ml': {'inference': {}}}}, {'_index': 'my_vector_index-01', '_id': 'ntmhrpYBca9xMcEAnock', '_score': 0.60257983, '_source': {'my_text': 'I’m The Dude. So, that’s what you call me. You know, that or, uh, His Dudeness, or, uh, Duder, or El Duderino, if you’re not into the whole brevity thing', 'my_metadata': 'The Dude', 'ml': {'inference': {}}}}]}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vhefCRd-mjk8"
   },
   "source": [
    "## Hybrid Searching (kNN + BM25) with RRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wLY8Q6tEmk06",
    "outputId": "3f1cc630-6e65-42b8-82eb-b83222fd43ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'_id': 'oNmhrpYBca9xMcEAnock',\n",
      "  '_index': 'my_vector_index-01',\n",
      "  '_score': 1.8420708,\n",
      "  'fields': {'my_metadata': ['Walter Sobchak'],\n",
      "             'my_text': ['What do you mean brought it bowling, Dude?']}},\n",
      " {'_id': 'odmhrpYBca9xMcEAnock',\n",
      "  '_index': 'my_vector_index-01',\n",
      "  '_score': 1.2540475,\n",
      "  'fields': {'my_metadata': ['Walter Sobchak'],\n",
      "             'my_text': ['Donny was a good bowler, and a good man. He was one '\n",
      "                         'of us. He was a man who loved the outdoors... and '\n",
      "                         'bowling, and as a surfer he explored the beaches of '\n",
      "                         'Southern California, from La Jolla to Leo Carrillo '\n",
      "                         'and... up to... Pismo']}}]\n"
     ]
    }
   ],
   "source": [
    "query = {\"match\": {\"my_text\": \"bowling\"}}   # Keyword search query\n",
    "\n",
    "knn = {\n",
    "    \"field\": \"my_vector\",\n",
    "    \"k\": 3,\n",
    "    \"num_candidates\": 5,\n",
    "    \"query_vector_builder\": {\n",
    "        \"text_embedding\": {\n",
    "            \"model_id\": \"sentence-transformers__all-distilroberta-v1\",\n",
    "            \"model_text\": \"He enjoyed the game\",    # Semantic search query\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n",
    "rank: {\"rrf\": {}}\n",
    "\n",
    "fields = [\"my_text\", \"my_metadata\"]\n",
    "\n",
    "\n",
    "response = es.search(\n",
    "    index=index_name, fields=fields, knn=knn, query=query, size=2, source=False\n",
    ")\n",
    "\n",
    "pprint(response[\"hits\"][\"hits\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HDBHn_kamlIL"
   },
   "source": [
    "## Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yVDMHuM3mla7",
    "outputId": "b39c13de-a97b-4112-b733-a246cdc7f364"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'_id': 'ndmhrpYBca9xMcEAnock',\n",
      "  '_index': 'my_vector_index-01',\n",
      "  '_score': 0.59394693,\n",
      "  'fields': {'my_metadata': ['The Dude'],\n",
      "             'my_text': [\"Hey, careful, man, there's a beverage here!\"]}}]\n"
     ]
    }
   ],
   "source": [
    "knn = {\n",
    "    \"field\": \"my_vector\",\n",
    "    \"k\": 1,\n",
    "    \"num_candidates\": 5,\n",
    "    \"query_vector_builder\": {\n",
    "        \"text_embedding\": {\n",
    "            \"model_id\": \"sentence-transformers__all-distilroberta-v1\",\n",
    "            \"model_text\": \"Did you bring the dog?\",\n",
    "        }\n",
    "    },\n",
    "    \"filter\": {\"term\": {\"my_metadata.keyword\": \"The Dude\"}},\n",
    "}\n",
    "\n",
    "fields = [\"my_text\", \"my_metadata\"]\n",
    "\n",
    "response = es.search(index=index_name, fields=fields, knn=knn, source=False)\n",
    "\n",
    "pprint(response[\"hits\"][\"hits\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N_Msyv4-m5ow"
   },
   "source": [
    "# Aggregrations\n",
    "and Select fields returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jbwinE0fm5-I",
    "outputId": "7ae0af99-3260-475b-98fe-2b5d8d165645"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'_id': 'oNmhrpYBca9xMcEAnock',\n",
      "  '_index': 'my_vector_index-01',\n",
      "  '_score': 0.74338245,\n",
      "  'fields': {'my_metadata': ['Walter Sobchak'],\n",
      "             'my_text': ['What do you mean brought it bowling, Dude?']}},\n",
      " {'_id': 'ndmhrpYBca9xMcEAnock',\n",
      "  '_index': 'my_vector_index-01',\n",
      "  '_score': 0.6028073,\n",
      "  'fields': {'my_metadata': ['The Dude'],\n",
      "             'my_text': [\"Hey, careful, man, there's a beverage here!\"]}}]\n"
     ]
    }
   ],
   "source": [
    "knn = {\n",
    "    \"field\": \"my_vector\",\n",
    "    \"k\": 2,\n",
    "    \"num_candidates\": 5,\n",
    "    \"query_vector_builder\": {\n",
    "        \"text_embedding\": {\n",
    "            \"model_id\": \"sentence-transformers__all-distilroberta-v1\",\n",
    "            \"model_text\": \"did you bring it?\",\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n",
    "aggs = {\"metadata\": {\"terms\": {\"field\": \"my_metadata.keyword\"}}}\n",
    "\n",
    "fields = [\"my_text\", \"my_metadata\"]\n",
    "\n",
    "response = es.search(index=index_name, fields=fields, aggs=aggs, knn=knn, source=False)\n",
    "\n",
    "pprint(response[\"hits\"][\"hits\"])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
